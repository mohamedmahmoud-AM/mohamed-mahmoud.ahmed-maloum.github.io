<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Zachary Teed</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zachary Teed</name>
              </p>
              <p>I am an autonomy engineering at <a href="https://www.skydio.com/">Skydio</a>.
              </p>
              <p> Previously, I graduated with a PhD in computer science from Princeton University where I was advised by Jia Deng. My research interests include optical flow, 3D reconstruction and SLAM.
              </p>

              <p> In 2022, I competed in the <a href="https://www.youtube.com/watch?v=VU6pdURPTGs">World Beer Mile Championships</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:zachteed@gmail.com">Email</a>
              </p>
            </td>
            <td style="padding:2.5%;width:25%;max-width:25%">
              <a href="images/Profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/dpvo.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2208.04726">
                <papertitle>DPVO: Deep Patch Visual Odometry</papertitle>
              </a>
              <br>
              <strong>Zachary Teed*, </strong> Lahav Lipson*, and Jia Deng
              <br>
              NeurIPS, 2023
              <br>
              <a href="https://arxiv.org/abs/2208.04726"> paper </a>  /
              <a href="https://github.com/princeton-vl/DPVO"> code</a>
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/droid.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2108.10869">
                <papertitle>DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras</papertitle>
              </a>
              <br>
              <strong>Zachary Teed </strong> and Jia Deng
              <br>
              NeurIPS, 2021
              <br>
              <a href="https://arxiv.org/abs/2108.10869"> paper </a>  /
              <a href="https://github.com/princeton-vl/DROID-SLAM"> code</a>
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/r3d.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2012.00726">
                <papertitle>RAFT3D: Scene Flow using Rigid Motion Embeddings </papertitle>
              </a>
              <br>
              <strong>Zachary Teed </strong> and Jia Deng
              <br>
              CVPR, 2021
              <br>
              <a href="https://arxiv.org/abs/2012.00726"> paper </a>  /
              <a href="https://github.com/princeton-vl/RAFT-3D"> code </a>
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tagentbackprop-1.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="">
                <papertitle>Tangent Space Backpropogation for 3D Transformation Groups </papertitle>
              </a>
              <br>
              <strong>Zachary Teed </strong> and Jia Deng
              <br>
              CVPR, 2021
              <br>
              <a href="https://arxiv.org/abs/2103.12032"> paper</a>  /
              <a href="https://github.com/princeton-vl/lietorch"> code</a>
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/RAFTv2-page-001.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2003.12039">
                <papertitle>RAFT: Recurrent All-Pairs Field Transforms for Optical Flow </papertitle>
              </a>
              <br>
              <strong>Zachary Teed </strong> and Jia Deng
              <br>
              ECCV 2020 <strong> Best Paper Award </strong>
              <br>
              <a href="https://arxiv.org/abs/2003.12039"> paper </a>  /
              <a href="https://github.com/princeton-vl/RAFT"> code </a>
              <p></p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DeepV2D.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1812.04605">
                <papertitle>DeepV2D: Video to Depth with Differentiable Structure from Motion </papertitle>
              </a>
              <br>
              <strong>Zachary Teed </strong> and Jia Deng
              <br>
              <em>ICLR</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/1812.04605"> paper </a>  /
              <a href="https://github.com/princeton-vl/DeepV2D"> code </a>
              <p></p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/MMOptimizer.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.sciencedirect.com/science/article/pii/S2215016116300395">
                <papertitle>A computationally efficient algorithm for fitting ion channel parameters</papertitle>
              </a>
              <br>
              <strong>Zachary Teed </strong> and Jonathan Silva
              <br>
              <em>MethodsX</em>, 2016
              <br>
              <a href="https://github.com/silvalab/MMOptimizer"> code </a>
              <p></p>
            </td>
          </tr>

      </td>
    </tr>
  </table>
</body>


<p align="center">
  <font size="2">
    Template from <a href="https://github.com/jonbarron/jonbarron_website">here.</a>
  </font>
</p>

</html>
